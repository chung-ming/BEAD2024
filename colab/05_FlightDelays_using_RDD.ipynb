{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suriarasai/BEAD2024/blob/main/colab/05_FlightDelays_using_RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resilient Distributed Data Set\n",
        "Resilient Distributed Datasets (RDDs) are collections of immutable JVM objects that are distributed across an Apache Spark cluster. An RDD is the fundamental dataset type of Apache Spark; any action on a Spark DataFrame eventually gets translated into a highly optimized execution of transformations and actions on RDDs."
      ],
      "metadata": {
        "id": "s3yyvElsbOku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup PySpark\n",
        "Spark requires a handful of environments to be present on the machine before we can use it. The below codes help to install pyspark and related tools."
      ],
      "metadata": {
        "id": "amqCrsezcvKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOuiptH23wSa",
        "outputId": "fd26372c-25dc-429c-9538-ed33842d8f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# install pyspark using pip\n",
        "!pip install --ignore-install -q pyspark\n",
        "# install findspark using pip\n",
        "!pip install --ignore-install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Session\n",
        "The below codes are used to create a Spark session object, and also set up related UI port."
      ],
      "metadata": {
        "id": "r0IKtztbbL-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark import SparkConf,SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "import collections\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Flight Delay\").config('spark.ui.port', '4050').getOrCreate()\n"
      ],
      "metadata": {
        "id": "l1I1VynS4JBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating RDD\n",
        "There are two ways to create an RDD in PySpark: we can either use the parallelize() method—a collection (list or an array of some elements) or reference a file (or files) located either locally or through an external source, as noted in subsequent recipes.\n",
        "\n",
        "Parallelized collections are created by calling SparkContext's parallelize method on an existing iterable or collection in your driver program. The elements of the collection are copied to form a distributed dataset that can be operated on in parallel.\n",
        "\n",
        "The following code snippet creates RDD (myRDD) using the sc.parallelize() method:"
      ],
      "metadata": {
        "id": "ZOwEqQRndtSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myRDD = spark.sparkContext.parallelize([('Suria', 21), ('Venkat', 18), ('Liu Fan',16), ('Bob', 18), ('Scott', 17)])\n",
        "myRDD.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJDeekWGeDLp",
        "outputId": "cbd0d73b-da82-4e2b-8a90-e2fe1282542b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Suria', 21), ('Venkat', 18), ('Liu Fan', 16), ('Bob', 18), ('Scott', 17)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Reading data from a file involves file besing stored locally or in hadoop or AWS S3 or Azure WASB or Google Cloud Storage or Data Bricks storage. Examples for the same are provided below:\n",
        "1. sc.textFile('/local folder/filename.csv')\n",
        "2. sc.textFile('hdfs://folder/filename.csv')\n",
        "3. sc.textFile('s3://bucket/folder/filename.csv')\n",
        "4. sc.textFile('wasb://bucket/folder/filename.csv')\n",
        "5. sc.textFile('gs://bucket/folder/filename.csv')\n",
        "6. sc.textFile('dbfs://folder/filename.csv')\n",
        "\n",
        "For this workshop, please use the data from GIT two files (airport-codes-na.txt and departuredelays.csv).\n",
        "\n",
        "Mount them into your google drive using the below file upload button.\n",
        "\n",
        "Note that the files can be copied from this [URL](https://github.com/suriarasai/BEAD2024/tree/main/data).\n",
        "\n",
        "To demonstrate the upload facility we will upload file airport-codes-na.txt via file explorer.\n",
        "\n"
      ],
      "metadata": {
        "id": "oTO4QCHufTaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Xm9v7izlhaQM",
        "outputId": "5b1c81ea-d15a-4af7-e442-e57752a20479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95e4bf5b-ef4c-463b-a252-d219dfb7234e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95e4bf5b-ef4c-463b-a252-d219dfb7234e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving airport-codes-na.txt to airport-codes-na.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhDLLbgX9oLZ",
        "outputId": "43e4fb2a-a184-4e02-be0d-9ac6f1cdb41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can also upload the folders in your mounted google drive as shown below."
      ],
      "metadata": {
        "id": "Ecih-YxZhbxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airportRDD = spark.sparkContext.textFile(\"/content/drive/MyDrive/data/airport-data/airport-codes-na.txt\").map(lambda element: element.split(\"\\t\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "CGdy5n-E4UyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the RDD\n",
        "Now since we are treating the data as a text file, we need to strip of the header rown in order to parse the rest of the records."
      ],
      "metadata": {
        "id": "sQ62aNvKsK_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airportRDD.take(5)\n"
      ],
      "metadata": {
        "id": "lDEJmxlE5VM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6047d182-450b-4424-b223-fdc55c21d14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['City', 'State', 'Country', 'IATA'],\n",
              " ['Abbotsford', 'BC', 'Canada', 'YXX'],\n",
              " ['Aberdeen', 'SD', 'USA', 'ABR'],\n",
              " ['Abilene', 'TX', 'USA', 'ABI'],\n",
              " ['Akron', 'OH', 'USA', 'CAK']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us take a look at the total number of records."
      ],
      "metadata": {
        "id": "IsRIwvof0W_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airportRDD.count()\n"
      ],
      "metadata": {
        "id": "Y2uHmPIR5YsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a099a20-d790-41f9-a1ce-d8c3c780638e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "527"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code returns the number of partitions in RDD"
      ],
      "metadata": {
        "id": "XUUguapH0bsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airportRDD.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIVT7wh-Mw5f",
        "outputId": "f35c3020-3f77-4c9d-c689-dd18bc041c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the RDD: flights\n",
        "flights = (\n",
        "    spark.sparkContext\n",
        "    .textFile('/content/drive/MyDrive/data/airport-data/departuredelays.csv')\n",
        "    .map(lambda element: element.split(\",\"))\n",
        ")"
      ],
      "metadata": {
        "id": "etMiFbOxubsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flights.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-acFQ2k_uvOh",
        "outputId": "9284ced6-e19a-4406-b6cc-06ddcea7ba80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['date', 'delay', 'distance', 'origin', 'destination'],\n",
              " ['01011245', '6', '602', 'ABE', 'ATL'],\n",
              " ['01020600', '-8', '369', 'ABE', 'DTW'],\n",
              " ['01021245', '-2', '602', 'ABE', 'ATL'],\n",
              " ['01020605', '-4', '602', 'ABE', 'ATL']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration\n",
        "Let us try some transformation functions on the Data Set.\n",
        "\n",
        "Airports in Washington State"
      ],
      "metadata": {
        "id": "75--XcQlJ11K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User filter() to filter where second column == \"WA\"\n",
        "(\n",
        "    airportRDD\n",
        "    .map(lambda c: (c[0], c[1]))\n",
        "    .filter(lambda c: c[1] == \"WA\")\n",
        "    .take(5)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTvNACubvTim",
        "outputId": "298d75a5-a40e-4637-8d92-fc5208418486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bellingham', 'WA'),\n",
              " ('Moses Lake', 'WA'),\n",
              " ('Pasco', 'WA'),\n",
              " ('Pullman', 'WA'),\n",
              " ('Seattle', 'WA')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time we try the flatmap."
      ],
      "metadata": {
        "id": "b1JPd8YBKGOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only second column == \"WA\",\n",
        "# select first two columns within the RDD,\n",
        "# and flatten out all values\n",
        "(\n",
        "    airportRDD\n",
        "    .filter(lambda c: c[1] == \"WA\")\n",
        "    .map(lambda c: (c[0], c[1]))\n",
        "    .flatMap(lambda x: x)\n",
        "    .take(10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy-LcHIRvZkE",
        "outputId": "8f6c18c8-f25f-4f5a-adf6-29093410f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bellingham',\n",
              " 'WA',\n",
              " 'Moses Lake',\n",
              " 'WA',\n",
              " 'Pasco',\n",
              " 'WA',\n",
              " 'Pullman',\n",
              " 'WA',\n",
              " 'Seattle',\n",
              " 'WA']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third column represent the countries and the unique countries this data set covers are:"
      ],
      "metadata": {
        "id": "WxXoP4NKKgCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide the distinct elements for the\n",
        "# third column of airports representing\n",
        "# countries\n",
        "(\n",
        "    airportRDD\n",
        "    .map(lambda c: c[2])\n",
        "    .distinct()\n",
        "    .take(5)\n",
        ")"
      ],
      "metadata": {
        "id": "WsSG_dbHvfSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6edbdc-df94-45aa-e0ef-5fddb07dc244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Country', 'Canada', 'USA']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of starting airports this  flight data covers."
      ],
      "metadata": {
        "id": "XReTexjWK2c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide a sample based on 0.001% the\n",
        "# flights RDD data specific to the fourth\n",
        "# column (origin city of flight)\n",
        "# without replacement (False) using random\n",
        "# seed of 123\n",
        "(\n",
        "    flights\n",
        "    .map(lambda c: c[3])\n",
        "    .sample(False, 0.001, 123)\n",
        "    .take(5)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdW5EuY7vkcR",
        "outputId": "a83bf227-001b-48f4-eb40-37a0e67463bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ABQ', 'AEX', 'AGS', 'ANC', 'ATL']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joining data related to KFK airport and newyork."
      ],
      "metadata": {
        "id": "xFC4eTVtLDuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flights data\n",
        "#  e.g. (u'JFK', u'01010900')\n",
        "flt = flights.map(lambda c: (c[3], c[0]))\n",
        "\n",
        "# Airports data\n",
        "# e.g. (u'JFK', u'NY')\n",
        "air = airportRDD.map(lambda c: (c[3], c[1]))\n",
        "\n",
        "# Execute inner join between RDDs\n",
        "flt.join(air).take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxub3LCxvqJh",
        "outputId": "7c0f1041-6a1a-4833-a60e-961b955e3086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ABE', ('01011245', 'PA')),\n",
              " ('ABE', ('01020600', 'PA')),\n",
              " ('ABE', ('01021245', 'PA')),\n",
              " ('ABE', ('01020605', 'PA')),\n",
              " ('ABE', ('01031245', 'PA'))]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Programatically controlling partitions:"
      ],
      "metadata": {
        "id": "sC9yRe-GLM2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's re-partition this to 8 so we can have 8\n",
        "# partitions\n",
        "flights2 = flights.repartition(8)\n",
        "\n",
        "# Checking the number of partitions for the flights2 RDD\n",
        "flights2.getNumPartitions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKyNT7Ccv0af",
        "outputId": "594c7d68-f7a7-4375-813c-ff55649e9b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add index column to existing RDD."
      ],
      "metadata": {
        "id": "UrXNoyRcLU1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View each row within RDD + the index\n",
        "# i.e. output is in form ([row], idx)\n",
        "ac = airportRDD.map(lambda c: (c[0], c[3]))\n",
        "ac.zipWithIndex().take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA0xYksMv34P",
        "outputId": "689c6a21-3dcf-42b6-eba3-ccf9ba75aa62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('City', 'IATA'), 0),\n",
              " (('Abbotsford', 'YXX'), 1),\n",
              " (('Aberdeen', 'ABR'), 2),\n",
              " (('Abilene', 'ABI'), 3),\n",
              " (('Akron', 'CAK'), 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join Airports in the Washington State and British Columbia"
      ],
      "metadata": {
        "id": "JrkCMXSNLcGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create `a` RDD of Washington airports\n",
        "a = (\n",
        "    airportRDD\n",
        "    .zipWithIndex()\n",
        "    .filter(lambda row, idx : idx > 0)\n",
        "    .map(lambda row, idx: row)\n",
        "    .filter(lambda c: c[1] == \"WA\")\n",
        ")\n",
        "\n",
        "# Create `b` RDD of British Columbia airports\n",
        "b = (\n",
        "    airportRDD\n",
        "    .zipWithIndex()\n",
        "    .filter(lambda row, idx: idx > 0)\n",
        "    .map(lambda row, idx: row)\n",
        "    .filter(lambda c: c[1] == \"BC\")\n",
        ")\n",
        "\n",
        "# Union WA and BC airports\n",
        "a.union(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IIRRsmAwhaW",
        "outputId": "5cbeb283-6fb7-4e0b-eb1c-06339a9b00fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UnionRDD[50] at union at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flights data\n",
        "#  e.g. (u'JFK', u'01010900')\n",
        "flt = flights.map(lambda c: (c[3], c[0]))\n",
        "\n",
        "# Airports data\n",
        "# e.g. (u'JFK', u'NY')\n",
        "air = airportRDD.map(lambda c: (c[3], c[1]))\n",
        "\n",
        "# Execute inner join between RDDs\n",
        "flt.join(air).take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TGLjCidxmYX",
        "outputId": "de23e596-4111-4a31-fee8-c9e497b7b30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ABE', ('01011245', 'PA')),\n",
              " ('ABE', ('01020600', 'PA')),\n",
              " ('ABE', ('01021245', 'PA')),\n",
              " ('ABE', ('01020605', 'PA')),\n",
              " ('ABE', ('01031245', 'PA'))]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the RDD: airports\n",
        "airports = (\n",
        "    spark.sparkContext\n",
        "    .textFile('/content/drive/MyDrive/data/airport-data/airport-codes-na.txt')\n",
        "    .map(lambda element: element.split(\"\\t\"))\n",
        ")\n",
        "\n",
        "airports.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1p88kf2x2C0",
        "outputId": "227ff26b-1615-4f6c-f564-93168947ceb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['City', 'State', 'Country', 'IATA'],\n",
              " ['Abbotsford', 'BC', 'Canada', 'YXX'],\n",
              " ['Aberdeen', 'SD', 'USA', 'ABR'],\n",
              " ['Abilene', 'TX', 'USA', 'ABI'],\n",
              " ['Akron', 'OH', 'USA', 'CAK']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the RDD: flights\n",
        "flights2 = (\n",
        "    spark.sparkContext\n",
        "     .textFile('/content/drive/MyDrive/data/airport-data/departuredelays.csv', minPartitions=8)\n",
        "    .map(lambda line: line.split(\",\"))\n",
        ")\n",
        "\n",
        "flights2.take(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLM5wUjjyEZ2",
        "outputId": "22f6b7b4-d970-4072-c413-33d0709e4238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['date', 'delay', 'distance', 'origin', 'destination'],\n",
              " ['01011245', '6', '602', 'ABE', 'ATL'],\n",
              " ['01020600', '-8', '369', 'ABE', 'DTW'],\n",
              " ['01021245', '-2', '602', 'ABE', 'ATL'],\n",
              " ['01020605', '-4', '602', 'ABE', 'ATL']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print to console the first 3 elements of\n",
        "# the airports RDD\n",
        "airportRDD.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYyIrEsQyb7f",
        "outputId": "a9cbac9d-04d5-49b8-9687-36e10d868ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['City', 'State', 'Country', 'IATA'],\n",
              " ['Abbotsford', 'BC', 'Canada', 'YXX'],\n",
              " ['Aberdeen', 'SD', 'USA', 'ABR']]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return all airports elements\n",
        "# filtered by WA state\n",
        "airportRDD.filter(lambda c: c[1] == \"WA\").collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NfNpu-yh8J",
        "outputId": "8be38032-438a-4002-cab7-5336574a9b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Bellingham', 'WA', 'USA', 'BLI'],\n",
              " ['Moses Lake', 'WA', 'USA', 'MWH'],\n",
              " ['Pasco', 'WA', 'USA', 'PSC'],\n",
              " ['Pullman', 'WA', 'USA', 'PUW'],\n",
              " ['Seattle', 'WA', 'USA', 'SEA'],\n",
              " ['Spokane', 'WA', 'USA', 'GEG'],\n",
              " ['Walla Walla', 'WA', 'USA', 'ALW'],\n",
              " ['Wenatchee', 'WA', 'USA', 'EAT'],\n",
              " ['Yakima', 'WA', 'USA', 'YKM']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return all airports elements\n",
        "# filtered by WA state\n",
        "airportRDD.filter(lambda c: c[1] == \"WA\").collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Lw27-byo_E",
        "outputId": "7c7299e7-fc99-4a73-96ca-aaed884b9b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Bellingham', 'WA', 'USA', 'BLI'],\n",
              " ['Moses Lake', 'WA', 'USA', 'MWH'],\n",
              " ['Pasco', 'WA', 'USA', 'PSC'],\n",
              " ['Pullman', 'WA', 'USA', 'PUW'],\n",
              " ['Seattle', 'WA', 'USA', 'SEA'],\n",
              " ['Spokane', 'WA', 'USA', 'GEG'],\n",
              " ['Walla Walla', 'WA', 'USA', 'ALW'],\n",
              " ['Wenatchee', 'WA', 'USA', 'EAT'],\n",
              " ['Yakima', 'WA', 'USA', 'YKM']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total delays of flights\n",
        "# between SEA (origin) and SFO (dest),\n",
        "# convert delays column to int\n",
        "# and summarize\n",
        "flights\\\n",
        " .filter(lambda c: c[3] == 'SEA' and c[4] == 'SFO')\\\n",
        " .map(lambda c: int(c[1]))\\\n",
        " .reduce(lambda x, y: x + y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZdZ7WL4yvWK",
        "outputId": "45f691a3-faef-449f-d574-5fe52dcc7195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22293"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write From RDD To File\n",
        "PySpark SequenceFile support loads an RDD of key-value pairs within Java, converts Writables to base Java types, and pickles the resulting Java objects using pickle. When saving an RDD of key-value pairs to SequenceFile, PySpark does the reverse. It unpickles Python objects into Java objects and then converts them to Writables. The following Writables are automatically converted:\n",
        "\n",
        "0. Writable /\tPython Type\n",
        "1. Text\tstr\n",
        "2. IntWritable\tint\n",
        "3. FloatWritable\tfloat\n",
        "4. DoubleWritable\tfloat\n",
        "5. BooleanWritable\tbool\n",
        "6. BytesWritable\tbytearray\n",
        "7. NullWritable\tNone\n",
        "8. MapWritable\tdict\n",
        "\n",
        "Similarly to text files, SequenceFiles can be saved and loaded by specifying the path. The key and value classes can be specified, but for standard Writables this is not required."
      ],
      "metadata": {
        "id": "gQie2h5b1nxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(range(1, 4)).map(lambda x: (x, \"a\" * x))\n",
        "rdd.saveAsSequenceFile(\"/content/drive/MyDrive/data/airport-data/sample.txt\")"
      ],
      "metadata": {
        "id": "kPkX6iYM2FxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Closing Comments\n",
        "RDDs are the most basic and low-level API, providing more control over the data but with lower-level optimizations. Also, RDD is slower than both Dataframes and Datasets to perform simple operations like grouping the data. Because RDD lacks query optimization and schema inferences.\n",
        "\n",
        "However, DataFrames provide a higher-level API that is optimized for performance and easier to work with for structured data.\n",
        "Workshop Ends Here"
      ],
      "metadata": {
        "id": "_nyIE0SR-8xQ"
      }
    }
  ]
}